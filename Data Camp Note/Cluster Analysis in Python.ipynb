{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns, pandas as pd\n",
    "# Import linkage and fcluster functions\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "# Use the linkage() function to compute distances\n",
    "Z = linkage(df, 'ward')\n",
    "\n",
    "# Generate cluster labels for each data point with two clusters\n",
    "df['cluster_labels'] = fcluster(Z, 2, criterion='maxclust')\n",
    "\n",
    "# Plot the points with seaborn\n",
    "sns.scatterplot(x='x', y='y', hue='cluster_labels', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means clustering in scipy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.vq import kmeans, vq\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns, pandas as pd\n",
    "centroids,_ = kmeans(df, 3)\n",
    "df['cluster_labels'],_ = vq(df, centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization of data\n",
    "* Process of recalling data to a standard deviation of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.vq import whiten\n",
    "scaled_data = whiten(data)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(data, label = 'original')\n",
    "plt.plot(scaled_data, label = 'scaled')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a distance matrix using linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.cluster.hierarchy.linkage(observations,\n",
    "                                method = 'single',\n",
    "                                metric = 'euclidean',\n",
    "                                optimal_ordercing = False)\n",
    "# Create cluster labels with fcluster\n",
    "scipy.cluster.hierarchy.fluster(distance_matrix,\n",
    "                                num_clusters,\n",
    "                                criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the fcluster and linkage functions\n",
    "from scipy.cluster.hierarchy import fcluster, linkage\n",
    "\n",
    "# Use the linkage() function\n",
    "distance_matrix = linkage(comic_con[['x_scaled', 'y_scaled']], \n",
    "                          method = 'complete', \n",
    "                          metric = 'euclidean')\n",
    "\n",
    "# Assign cluster labels\n",
    "comic_con['cluster_labels'] = fcluster(distance_matrix, \n",
    "                                       2, \n",
    "                                       criterion='maxclust')\n",
    "\n",
    "# Plot clusters\n",
    "sns.scatterplot(x='x_scaled', y='y_scaled', \n",
    "                hue='cluster_labels', \n",
    "                data = comic_con)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a dendrogram in Scipy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram\n",
    "Z = linkage(df[['x_whiten', 'y_whiten']],\n",
    "            methord = 'ward',\n",
    "            metric = 'euclidean')\n",
    "dn = dendrogram(Z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the kmeans and vq functions\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "\n",
    "# Generate cluster centers\n",
    "cluster_centers, distortion = kmeans(comic_con[['x_scaled', 'y_scaled']], 2)\n",
    "\n",
    "# Assign cluster labels\n",
    "comic_con['cluster_labels'], distortion_list = vq(comic_con[['x_scaled', 'y_scaled']], \n",
    "                                                  cluster_centers)\n",
    "\n",
    "# Plot clusters\n",
    "sns.scatterplot(x='x_scaled', y='y_scaled', \n",
    "                hue='cluster_labels', data = comic_con)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = []\n",
    "num_clusters = range(1, 7)\n",
    "\n",
    "# Create a list of distortions from the kmeans function\n",
    "for i in num_clusters:\n",
    "    cluster_centers, distortion = kmeans(comic_con[['x_scaled', 'y_scaled']], i)\n",
    "    distortions.append(distortion)\n",
    "\n",
    "# Create a data frame with two lists - num_clusters, distortions\n",
    "elbow_plot = pd.DataFrame({'num_clusters': num_clusters, 'distortions': distortions})\n",
    "\n",
    "# Creat a line plot of num_clusters and distortions\n",
    "sns.lineplot(x='num_clusters', y='distortions', data = elbow_plot)\n",
    "plt.xticks(num_clusters)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import random class\n",
    "from numpy import random\n",
    "\n",
    "# Initialize seed\n",
    "random.seed([1, 2, 1000])\n",
    "\n",
    "# Run kmeans clustering\n",
    "cluster_centers, distortion = kmeans(comic_con[['x_scaled', 'y_scaled']], 2)\n",
    "comic_con['cluster_labels'], distortion_list = vq(comic_con[['x_scaled', 'y_scaled']], cluster_centers)\n",
    "\n",
    "# Plot the scatterplot\n",
    "sns.scatterplot(x='x_scaled', y='y_scaled', \n",
    "                hue='cluster_labels', data = comic_con)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a random seed in numpy\n",
    "random.seed([1000,2000])\n",
    "\n",
    "# Fit the data into a k-means algorithm\n",
    "cluster_centers,_ = kmeans(fifa[['scaled_def', 'scaled_phy']], 3)\n",
    "\n",
    "# Assign cluster labels\n",
    "fifa['cluster_labels'], _ = vq(fifa[['scaled_def', 'scaled_phy']], cluster_centers)\n",
    "\n",
    "# Display cluster centers \n",
    "print(fifa[['scaled_def', 'scaled_phy', 'cluster_labels']].groupby('cluster_labels').mean())\n",
    "\n",
    "# Create a scatter plot through seaborn\n",
    "sns.scatterplot(x='scaled_def', y='scaled_phy', hue='cluster_labels', data=fifa)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract RGB values from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import image class of matplotlib\n",
    "import matplotlib.image as img\n",
    "\n",
    "# Read batman image and print dimensions\n",
    "batman_image = img.imread('batman.jpg')\n",
    "print(batman_image.shape)\n",
    "\n",
    "# Store RGB values of all pixels in lists r, g and b\n",
    "for row in batman_image:\n",
    "    for temp_r, temp_g, temp_b in row:\n",
    "        r.append(temp_r)\n",
    "        g.append(temp_g)\n",
    "        b.append(temp_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = []\n",
    "num_clusters = range(1, 7)\n",
    "\n",
    "# Create a list of distortions from the kmeans function\n",
    "for i in num_clusters:\n",
    "    cluster_centers, distortion = kmeans(batman_df[['scaled_red', \n",
    "                                                    'scaled_blue', \n",
    "                                                    'scaled_green']], i)\n",
    "    distortions.append(distortion)\n",
    "\n",
    "# Create a data frame with two lists, num_clusters and distortions\n",
    "elbow_plot = pd.DataFrame({'num_clusters': num_clusters, \n",
    "                           'distortions': distortions})\n",
    "\n",
    "# Create a line plot of num_clusters and distortions\n",
    "sns.lineplot(x='num_clusters', y='distortions', data = elbow_plot)\n",
    "plt.xticks(num_clusters)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get standard deviations of each color\n",
    "r_std, g_std, b_std = batman_df[['red', 'green', 'blue']].std()\n",
    "\n",
    "for cluster_center in cluster_centers:\n",
    "    scaled_r, scaled_g, scaled_b = cluster_center\n",
    "    # Convert each standardized value to scaled value\n",
    "    colors.append((\n",
    "        scaled_r * r_std / 255,\n",
    "        scaled_g * g_std / 255,\n",
    "        scaled_b * b_std / 255\n",
    "    ))\n",
    "\n",
    "# Display colors of cluster centers\n",
    "plt.imshow([colors])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TfidfVectorizer class from sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df = 0.75, min_df= 0.1, \n",
    "                                   max_features = 50, \n",
    "                                   tokenizer = remove_noise)\n",
    "\n",
    "# Use the .fit_transform() method on the list plots\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 2\n",
    "\n",
    "# Generate cluster centers through the kmeans function\n",
    "cluster_centers, distortion = kmeans(tfidf_matrix.todense(), num_clusters)\n",
    "\n",
    "# Generate terms from the tfidf_vectorizer object\n",
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    # Sort the terms and print top 3 terms\n",
    "    center_terms = dict(zip(terms, list(cluster_centers[i])))\n",
    "    sorted_terms = sorted(center_terms, key=center_terms.get, reverse=True)\n",
    "    print(sorted_terms[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create centroids with kmeans for 2 clusters\n",
    "cluster_centers,_ = kmeans(fifa[scaled_features], 2)\n",
    "\n",
    "# Assign cluster labels and print cluster centers\n",
    "fifa['cluster_labels'], _ = vq(fifa[scaled_features], cluster_centers)\n",
    "print(fifa.groupby('cluster_labels')[scaled_features].mean())\n",
    "\n",
    "# Plot cluster centers to visualize clusters\n",
    "fifa.groupby('cluster_labels')[scaled_features].mean().plot(legend=True, kind='bar')\n",
    "plt.show()\n",
    "\n",
    "# Get the name column of first 5 players in each cluster\n",
    "for cluster in fifa['cluster_labels'].unique():\n",
    "    print(cluster, fifa[fifa['cluster_labels'] == cluster]['name'].values[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
