{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sales['revenue'].sum()\n",
    "# 453$\n",
    "sales['revenue'] = sales['revenue'].str.strip($)\n",
    "sales['revenue'] = sales['revenue'].astype('int')\n",
    "# 453 get ride of the $ sign\n",
    "assert sales['revenue'].dtype == 'int'\n",
    "# Verify that revenue is now an integer, assert returns nothing if the condition was met"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Range Constrains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "today_date = dt.date.today()\n",
    "user['description_date'] = user[uer['description_date'] > dt.date.today()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with out of range data\n",
    "* Dropping data \n",
    "* Setting custom minimuns and maximuns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data \n",
    "movies[movies['avg_rating'] > 5]\n",
    "\n",
    "# Filtering \n",
    "movies = movies[movies['avg_rating'] <= 5]\n",
    "\n",
    "# Drop value using .drop()\n",
    "movies.drop(movies[movies['avg_rating'] > 5].index, inplace = True)\n",
    "\n",
    "# Convert avg_rating > 5 to 5\n",
    "movies.loc[movies['avg_rating'] > 5, 'avg_rating'] = 5\n",
    "\n",
    "#convert to DateTime \n",
    "user['description_date'] = pd.to_datetime(user['description_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "today_date = dt.date.today()\n",
    "\n",
    "# Drop data\n",
    "# Filtering\n",
    "user['description_date'] = user[user['description_date'] < today_date]\n",
    "# .drop()\n",
    "user['description_date'].drop(user[user['description_date'] > today_date].index, \n",
    "                              inplace = True)\n",
    "\n",
    "#Filtering\n",
    "user['description_date'].loc[user['description_date'] > today_date, \n",
    "                             'description_date'] = today_date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicate values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get duplicate rows\n",
    "duplicates = height_weight.duplicated()\n",
    "height_weight[duplicates]\n",
    "\n",
    "# Column name to check for duplications\n",
    "column_names = ['first_name', 'last_name', 'address']\n",
    "duplicates = height_weight.duplicated(subset = column_names, keep = False)\n",
    "# Sort values\n",
    "height_weight[duplicates].sort_values(by = 'first_name')\n",
    "# Drop duplicates\n",
    "height_weight.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby() and agg() methods\n",
    "column_name = ['frist_name', 'last_name', 'address']\n",
    "summaries = {'height':'max', 'weight':'mean'}\n",
    "height_weight = height_weight.groupby(by = column_name).agg(summaries).rest_index()\n",
    "\n",
    "# Make sure aggregation was done \n",
    "duplicates = height_weight.duplicated(subset = column_name, keep = False)\n",
    "height_weight[duplicates].sort_values(by = 'first_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2\n",
    "* Predefined finite set of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find inconsistent categories\n",
    "inconsistant_categories = set(study_data['blood_type']).difference(categories['blood_type'])\n",
    "inconsistent_rows = study_data['blood_type'].isin(inconsistant_categories)\n",
    "study_data[inconsistent_rows]\n",
    "\n",
    "# Get consistant data only \n",
    "consistant_data = study_data[~inconsistent_rows]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical variable\n",
    "* Value inconsistency\n",
    "* Collapsing too many categories to few\n",
    "* Making sure the data was in the right type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capitalize \n",
    "marriage_states['marriage_states'] = marriage_states['marriage_states'].str.upper()\n",
    "marriage_states['marriage_states'].value_counts()\n",
    "\n",
    "# Lowercase\n",
    "marriage_states['marriage_states'] = marriage_states['marriage_states'].str.upper()\n",
    "marriage_states['marriage_states'].value_counts()\n",
    "\n",
    "# Strip all space \n",
    "marriage_states['marriage_states'] = marriage_states['marriage_states'].str.strip()\n",
    "marriage_states['marriage_states'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using cut() --- create category ranges and names \n",
    "ranges = [0, 20000, 50000, np.inf]\n",
    "group_names = ['0-200k', '200k-500k', '500k+']\n",
    "# Creating income group column\n",
    "demographics['income_group'] = pd.cut(demographics['household_group'], \n",
    "                                     bins = ranges,\n",
    "                                     labels = group_names)\n",
    "demographics[['income_group', 'household_group']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map categories to fewer ones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating mapping dictionary and replace \n",
    "\n",
    "# Create ranges for categories\n",
    "label_ranges = [0, 60, 180, np.inf]\n",
    "label_names = ['short', 'medium', 'long']\n",
    "\n",
    "# Create wait_type column\n",
    "airlines['wait_type'] = pd.cut(airlines['wait_min'], \n",
    "                               bins = label_ranges, \n",
    "                               labels = label_names)\n",
    "\n",
    "# Create mappings and replace\n",
    "mappings = {'Monday':'weekday', 'Tuesday':'weekday', 'Wednesday': 'weekday', \n",
    "            'Thursday': 'weekday', 'Friday': 'weekday', \n",
    "            'Saturday': 'weekend', 'Sunday': 'weekend'}\n",
    "\n",
    "airlines['day_week'] = airlines['day'].replace(mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "phones['phone_number'] = phones['phone_number'].str.strip('+', '00')\n",
    "phones['phone_number'] = phones['phone_number'].str.strip('+', '')\n",
    "\n",
    "# Replace phone numbers with lower than 10 digits to NaN\n",
    "digits = phones['phone_number'].str.len()\n",
    "phones.loc[digits < 10, 'phone_number'] = np.nan\n",
    "\n",
    "# Assert check \n",
    "sanity_check = phones['phone_number'].str.len()\n",
    "assert sanity_check.min() >= 10\n",
    "assert phones['phone_number'].str.contains('+ | -').any() == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular expressions in action\n",
    "phones['phone_number'] = phones['phone_number'].str.replace(r'\\D+', '')\n",
    "# Replace anything that is not a number "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3\n",
    "### Uniformity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datetime formating\n",
    "25-21-2019 %d-%m-%Y\n",
    "December 25th 2019 %c\n",
    "12-25-2019 %m-%d-%Y\n",
    "# Treating data \n",
    "birthdays['Birthday'] = pd.to_datetime(birthdays['Birthday'],\n",
    "                                       infer_datetime_format = True,\n",
    "                                       errors = 'coerce')\n",
    "# Convert format\n",
    "birthdays['Birthday'] = birthdays['Birthday'].dt.strftime('%d-%m-%Y')\n",
    "brithdays.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross field validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import datetime as dt\n",
    "\n",
    "users['birthday'] = pd.to_datetime(users['birthday'])\n",
    "today = dt.date.today()\n",
    "# Manualy calculate the difference\n",
    "age_manual = today.year - users['birthday'].dt.year\n",
    "# Find inconsistance\n",
    "age_equ = age_manual == users['Age']\n",
    "# Filter out the rows with inconsistant ages\n",
    "inconsistant_age = users[~age_equ]\n",
    "consistant_age[age_equ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completeness\n",
    "* Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missingno package\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "msno.matrix(airquality)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate missing and complete values inside\n",
    "missing = airquality[airquality['CO2'].isna()]\n",
    "complete = airquality[~airquality['CO2'].isna()]\n",
    "# sort values in the matrix \n",
    "sorted_quality = quality.sort_values(by = 'Temperature')\n",
    "msno.matrix(sorted_quality)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missingness types \n",
    "* Missing completely at random (MCAR)\n",
    "\n",
    "    Data entry errors when inputting data\n",
    "    \n",
    "* Missing at random (MAR)\n",
    "* Missing not at random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airquality_drop = airquality.dropna(subset = ['CO2'])\n",
    "# or calculate the mean value \n",
    "co2_mean = airquality['CO2'].mean()\n",
    "airquality_imputed = airquality.fillna({'CO2':co2_mean})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4\n",
    "### Comparing strings\n",
    "* Minimun edit distance\n",
    "\n",
    "Possible packages: nltk, fuzzywuzzy, textdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "fuzzy.WRatio('Reeding', 'Reading')\n",
    "\n",
    "category['state'] # with the right type\n",
    "survey['state'] # with hundurds of typos\n",
    "\n",
    "# Collapsing all of the state\n",
    "for state in categories['state']:\n",
    "    # Find potential matches in states with typos\n",
    "    matches = process.extract(state, survey['state'], limit = survey.shape[0])\n",
    "    \n",
    "    # For each potential match match\n",
    "    for potential_match in matches:\n",
    "        \n",
    "        # If high similarity score \n",
    "        if potential_match[1] > 80:\n",
    "            \n",
    "            #Replace typo with the right category\n",
    "            survey.loc[survey['state'] == potential_match[0], 'state'] = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['asian', 'american', 'italian']\n",
    "\n",
    "# For each correct cuisine_type in categories\n",
    "for cuisine in categories:\n",
    "  # Find matches in cuisine_type of restaurants\n",
    "  matches = process.extract(cuisine, restaurants['cuisine_type'], \n",
    "                            limit = restaurants.shape[0])\n",
    "  \n",
    "  # For each possible_match with similarity score >= 80\n",
    "  for possible_match in matches:\n",
    "    if possible_match[1] >= 80:\n",
    "      # Find matching cuisine type\n",
    "      matching_cuisine = restaurants['cuisine_type'] == possible_match[0]\n",
    "      restaurants.loc[matching_cuisine, 'cuisine_type'] = cuisine\n",
    "\n",
    "# Print unique values to confirm mapping\n",
    "print(restaurants['cuisine_type'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating pairs\n",
    "import recordlinkage\n",
    "indexer = recordlinkage.Index()\n",
    "\n",
    "indexer.block('state')\n",
    "pairs = indexer.index(census_A, census_B)\n",
    "\n",
    "# Creating a compare object \n",
    "compare_cl = recordlinkage.Compare()\n",
    "\n",
    "# Find exact matches of pairs \n",
    "compare_cl.exact('date_of_birth', 'date_of_birth', label = 'date_of_birth')\n",
    "compare_cl.exact('state', 'state', label = 'state')\n",
    "\n",
    "compare_cl.string('surname', 'surname', threshold = 0.85, label = 'surname')\n",
    "\n",
    "# Find matches \n",
    "potential_matches = compare_cl.compute(pairs, census_A, census_B)\n",
    "\n",
    "# Find only pair we want \n",
    "potential_matches[potential_matches.sum(axis = 1) >= 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linking DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indeces\n",
    "matches.index\n",
    "# Get indeces from census_B only\n",
    "duplicate_rows = matches.index.get_level_values(1)\n",
    "print(census_B_index)\n",
    "\n",
    "# Find duplicates in census_B\n",
    "census_B_duplicates = census_B[census_B.index.isin(duplicates_rows)]\n",
    "\n",
    "# Finding new rows in census_B\n",
    "census_B_new = census_B[~census_B.index.isin(duplicates_rows)]\n",
    "\n",
    "# Link your DataFrames\n",
    "full_census = census_A.append(census.B_new)\n",
    "\n",
    "\n",
    "\n",
    "# Generate potential matches \n",
    "potential_matches = compare_cl.compute(full_pairs, census_A, census_B)\n",
    "\n",
    "# Isolate matches with matching values for 3 or more columns \n",
    "matches = potential_matches[potential_matches.sum(axis = 1) >= 3]\n",
    "\n",
    "# Geting ndex for matching census_B rows only\n",
    "duplicate_rows = matches.index.get_level_values(1)\n",
    "\n",
    "# Finding new rows in census_B\n",
    "census_B_new = census_B[~census_B.index.isin(duplicates_rows)]\n",
    "\n",
    "# Link your DataFrames\n",
    "full_census = census_A.append(census.B_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization\n",
    "\n",
    "## Chapter 1: Common Data Cleaning Problems\n",
    "* Data type constrains \n",
    "* Data range constrains \n",
    "* Uniqueness constains\n",
    "\n",
    "## Chapter 2: Text and Categorical data problems \n",
    "* Membership constrains\n",
    "* Categorical variables\n",
    "* Cleaning text data\n",
    "\n",
    "## Chapter 3: Advance Data Cleaning Problems \n",
    "* Uniformity\n",
    "* Cross field validation\n",
    "* Completeness\n",
    "\n",
    "## Chapter 4: Record linkage\n",
    "* Generate pairs \n",
    "* Compare pairs\n",
    "* Score pairs\n",
    "* Link data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
